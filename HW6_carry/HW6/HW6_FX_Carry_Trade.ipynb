{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# HW6 FX Carry Strategy (GBP Funding)\n\nThis notebook implements the weekly FX carry strategy with GBP funding and outputs performance artifacts to `outputs/`."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "\nimport os\nfrom pathlib import Path\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\npd.set_option('display.max_columns', 200)\npd.set_option('display.width', 200)\n\nBASE = Path('.').resolve()\nOUT = BASE / 'outputs'\nFIG = OUT / 'figures'\nOUT.mkdir(exist_ok=True)\nFIG.mkdir(parents=True, exist_ok=True)\n\nprint('Working directory:', BASE)\nprint('Data inventory:')\nfor folder, pattern in [('data', '*'), ('data_clean', '*')]:\n    files = sorted((BASE / folder).glob(pattern))\n    print(f'  {folder}/ ({len(files)} files)')\n    for f in files:\n        print('   -', f.name)\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "\n# --- Load and standardize data ---\n\ndef load_ois(data_clean_dir: Path) -> pd.Series:\n    cands = sorted(data_clean_dir.glob('*IUDSOIA*.parquet')) + sorted(data_clean_dir.glob('*IUDSOIA*.csv'))\n    if not cands:\n        raise FileNotFoundError('No OIS file matching *IUDSOIA* found in data_clean/')\n    fp = cands[0]\n    if fp.suffix == '.parquet':\n        df = pd.read_parquet(fp)\n    else:\n        df = pd.read_csv(fp)\n    if isinstance(df.index, pd.DatetimeIndex):\n        idx = pd.to_datetime(df.index).tz_localize(None)\n        val_col = df.columns[0]\n        s = pd.Series(df[val_col].values, index=idx, name='ois')\n    else:\n        date_col = next((c for c in df.columns if str(c).upper() in {'DATE','DT','TIME','DATETIME'}), df.columns[0])\n        val_candidates = [c for c in df.columns if c != date_col]\n        val_col = next((c for c in val_candidates if 'IUDSOIA' in str(c).upper() or 'SONIA' in str(c).upper() or 'VALUE' in str(c).upper()), val_candidates[0])\n        s = pd.Series(pd.to_numeric(df[val_col], errors='coerce').values, index=pd.to_datetime(df[date_col], errors='coerce'), name='ois')\n    s = s.sort_index().dropna()\n    # Convert percent-like values to decimal if needed\n    if s.median() > 1:\n        s = s / 100.0\n    return s\n\n\ndef load_fx_usd_per_ccy(data_clean_dir: Path, currencies) -> pd.DataFrame:\n    # prefer already standardized USD/CCY panel\n    cands = sorted(data_clean_dir.glob('*edi*cur*usd_per_ccy*wide*.parquet'))\n    if cands:\n        df = pd.read_parquet(cands[0])\n        fx = df.copy()\n        if not isinstance(fx.index, pd.DatetimeIndex):\n            fx.index = pd.to_datetime(fx.index, errors='coerce')\n        fx.index = fx.index.tz_localize(None)\n    else:\n        cands = sorted(data_clean_dir.glob('*EDI*CUR*.parquet')) + sorted(data_clean_dir.glob('*edi*cur*.parquet'))\n        if not cands:\n            raise FileNotFoundError('No FX file matching *EDI*CUR* found in data_clean/')\n        df = pd.read_parquet(cands[0])\n        if {'date','ccy','value'}.issubset(set(df.columns)):\n            fx = df.pivot(index='date', columns='ccy', values='value')\n            fx.index = pd.to_datetime(fx.index, errors='coerce').tz_localize(None)\n        else:\n            if 'date' in df.columns:\n                df = df.set_index('date')\n            fx = df.copy()\n            fx.index = pd.to_datetime(fx.index, errors='coerce').tz_localize(None)\n    fx = fx.sort_index()\n    fx.columns = [str(c).upper().strip() for c in fx.columns]\n    fx = fx.apply(pd.to_numeric, errors='coerce')\n\n    # Keep only required currencies plus GBP\n    keep = sorted(set(currencies + ['GBP']))\n    for c in keep:\n        if c not in fx.columns:\n            fx[c] = np.nan\n    fx = fx[keep]\n\n    # sanity-based orientation check on GBP\n    gbp = fx['GBP'].dropna()\n    if not gbp.empty:\n        med = gbp.median()\n        if med < 0.7:  # likely GBP per USD; invert to USD per GBP\n            fx = 1.0 / fx\n            print('FX panel appears quoted as CCY per USD; inverted to USD per CCY.')\n        else:\n            print('FX panel appears quoted as USD per CCY; no inversion applied.')\n    else:\n        print('Warning: GBP series unavailable for FX orientation check.')\n    return fx\n\n\ndef parse_curve_file(fp: Path) -> pd.DataFrame:\n    raw = pd.read_csv(fp)\n    out = []\n    cols = list(raw.columns)\n    # Expect pairs of date/value columns named like GTTRY1YR Govt, Unnamed:1, GTTRY5YR Govt, ...\n    for i in range(0, len(cols), 2):\n        c_date = cols[i]\n        c_val = cols[i+1] if i+1 < len(cols) else None\n        if c_val is None:\n            continue\n        name = str(c_date).upper().replace(' GOVT','').strip()\n        # extract currency code and tenor\n        import re\n        m = re.search(r'GT([A-Z]{3})(\\d+)(Y|YR)', name)\n        if m is None:\n            continue\n        ccy = m.group(1)\n        tenor = float(m.group(2))\n        tmp = pd.DataFrame({\n            'date': pd.to_datetime(raw[c_date], errors='coerce'),\n            'rate': pd.to_numeric(raw[c_val], errors='coerce'),\n            'ccy': ccy,\n            'tenor': tenor\n        })\n        tmp = tmp.dropna(subset=['date','rate'])\n        out.append(tmp)\n    if not out:\n        raise ValueError(f'No parsable curve columns in {fp.name}')\n    return pd.concat(out, ignore_index=True)\n\n\ndef load_em_curves(data_dir: Path) -> pd.DataFrame:\n    files = sorted(data_dir.glob('*Emerging*Mkt*YC*.csv'))\n    if not files:\n        raise FileNotFoundError('No curve files matching *Emerging*Mkt*YC* in data/')\n    parts = [parse_curve_file(f) for f in files]\n    df = pd.concat(parts, ignore_index=True)\n    df['date'] = pd.to_datetime(df['date']).dt.tz_localize(None)\n    # clean percent vs decimal\n    if df['rate'].median() > 1:\n        df['rate'] = df['rate'] / 100.0\n    # collapse duplicates by average\n    df = df.groupby(['date','ccy','tenor'], as_index=False)['rate'].mean()\n    return df\n\nEM_CCY = ['BRL','NGN','PKR','TRY','ZAR']\nois = load_ois(BASE/'data_clean')\nfx = load_fx_usd_per_ccy(BASE/'data_clean', EM_CCY)\ncurves = load_em_curves(BASE/'data')\n\nprint('OIS:', ois.index.min().date(), 'to', ois.index.max().date(), 'obs=', len(ois))\nprint('FX:', fx.index.min().date(), 'to', fx.index.max().date(), 'obs=', len(fx), 'cols=', list(fx.columns))\nprint('Curves sample:')\nprint(curves.head())\nprint('Curve currencies:', sorted(curves.ccy.unique()))\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "\n# --- Weekly alignment (Wednesdays with +/- 2 day tolerance, prefer delaying) ---\n\ndef align_to_weekly_wed(series_or_df, start, end):\n    target = pd.date_range(start=start, end=end, freq='W-WED')\n    idx = series_or_df.index\n    out_vals, out_dates = [], []\n    for d in target:\n        choices = [d + pd.Timedelta(days=k) for k in [0,1,2,-1,-2]]\n        chosen = next((c for c in choices if c in idx), None)\n        if chosen is None:\n            continue\n        out_dates.append(d)\n        out_vals.append(series_or_df.loc[chosen])\n    if isinstance(series_or_df, pd.Series):\n        return pd.Series(out_vals, index=pd.DatetimeIndex(out_dates), name=series_or_df.name)\n    return pd.DataFrame(out_vals, index=pd.DatetimeIndex(out_dates), columns=series_or_df.columns)\n\ncurve_wide = curves.pivot_table(index=['date','ccy'], columns='tenor', values='rate', aggfunc='mean').sort_index()\n\ncommon_start = max(ois.index.min(), fx.index.min(), curves['date'].min())\ncommon_end = min(ois.index.max(), fx.index.max(), curves['date'].max())\n\nois_w = align_to_weekly_wed(ois, common_start, common_end)\nfx_w = align_to_weekly_wed(fx, common_start, common_end)\ndates = ois_w.index.intersection(fx_w.index)\n\n# Weekly curves per ccy, but do NOT force intersection across currencies\ncurve_weekly = {}\nfor c in EM_CCY:\n    if c not in curve_wide.index.get_level_values('ccy'):\n        continue\n    cdf = curve_wide.xs(c, level='ccy', drop_level=True).sort_index()\n    cw = align_to_weekly_wed(cdf, common_start, common_end)\n    curve_weekly[c] = cw.reindex(dates).ffill()\n\nois_w = ois_w.reindex(dates).ffill()\nfx_w = fx_w.reindex(dates).ffill()\n\nprint('Weekly aligned dates:', len(dates), dates.min().date(), 'to', dates.max().date())\nfor c in EM_CCY:\n    if c in curve_weekly:\n        print(f'{c} curve non-missing rows:', int(curve_weekly[c][5.0].notna().sum()) if 5.0 in curve_weekly[c].columns else 0)\nprint('Missing FX counts:')\nprint(fx_w[EM_CCY + ['GBP']].isna().sum())\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "\n# --- Curve utilities (bootstrap-ish discounting + bond pricing) ---\n\ndef interp_rate(tenors, rates, t):\n    tenors = np.array(tenors, dtype=float)\n    rates = np.array(rates, dtype=float)\n    m = np.isfinite(tenors) & np.isfinite(rates)\n    tenors, rates = tenors[m], rates[m]\n    if len(tenors) == 0:\n        return np.nan\n    order = np.argsort(tenors)\n    tenors, rates = tenors[order], rates[order]\n    return float(np.interp(t, tenors, rates, left=rates[0], right=rates[-1]))\n\n\ndef bootstrap_discount_from_par(par_curve: pd.Series, freq=4, max_t=5.0):\n    # Build quarterly grid discount factors from interpolated par rates\n    times = np.arange(1/freq, max_t + 1e-12, 1/freq)\n    dfs = {}\n    for t in times:\n        s = interp_rate(par_curve.index.values, par_curve.values, t)\n        c = s / freq\n        # par pricing: 1 = c*sum_{i=1}^{n-1}DF_i + (1+c)*DF_n\n        prev_times = times[times < t]\n        pv_cpn_prev = sum(c * dfs[pt] for pt in prev_times)\n        df_t = (1.0 - pv_cpn_prev) / (1.0 + c)\n        dfs[t] = max(df_t, 1e-10)\n    return pd.Series(dfs)\n\n\ndef price_fixed_bond(coupon_rate, rem_t, par_curve, freq=4):\n    pay_times = np.arange(1/freq, rem_t + 1e-12, 1/freq)\n    if len(pay_times) == 0:\n        return 1.0\n    zcb = bootstrap_discount_from_par(par_curve, freq=freq, max_t=max(5.0, rem_t+0.25))\n    # interpolate discount factors on needed times\n    z_times = zcb.index.values\n    z_vals = zcb.values\n    dfs = np.interp(pay_times, z_times, z_vals, left=z_vals[0], right=z_vals[-1])\n    c = coupon_rate / freq\n    cash = np.full(len(pay_times), c)\n    cash[-1] += 1.0\n    return float(np.sum(cash * dfs))\n\n# sanity check: 5Y par bond should be close to 1 on same curve\nsanity = []\nfor c in EM_CCY:\n    if c not in curve_weekly:\n        continue\n    row = curve_weekly[c].iloc[0].dropna()\n    if row.empty:\n        continue\n    s5 = interp_rate(row.index.values, row.values, 5.0)\n    p = price_fixed_bond(s5, 5.0, row, freq=4)\n    sanity.append((c, s5, p))\nsanity_df = pd.DataFrame(sanity, columns=['ccy','s5','par_price'])\nprint(sanity_df)\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "\n# --- Strategy backtest ---\n\nrecords = []\nweekly_port_ret = []\nused_funding_proxy = True  # GBP swap curve not available in data set\n\nfor i in range(len(dates)-1):\n    t0, t1 = dates[i], dates[i+1]\n    ois_rate = float(ois_w.loc[t0])\n    fund_spread = ois_rate + 0.005  # OIS + 50bp\n\n    ccy_rets = {}\n    for c in EM_CCY:\n        if c not in curve_weekly:\n            continue\n        crv0 = curve_weekly[c].loc[t0].dropna()\n        crv1 = curve_weekly[c].loc[t1].dropna()\n        if crv0.empty or crv1.empty:\n            continue\n        s5_lend = interp_rate(crv0.index.values, crv0.values, 5.0)\n        s5_fund = ois_rate  # fallback threshold proxy since GBP swap curve unavailable\n        active = bool(np.isfinite(s5_lend) and np.isfinite(s5_fund) and (s5_lend >= s5_fund + 0.005))\n\n        usd0 = fx_w.at[t0, c]\n        usd1 = fx_w.at[t1, c]\n        gbp0 = fx_w.at[t0, 'GBP']\n        gbp1 = fx_w.at[t1, 'GBP']\n        if not np.isfinite(usd0) or not np.isfinite(usd1) or not np.isfinite(gbp0) or not np.isfinite(gbp1):\n            active = False\n\n        pnl_usd = 0.0\n        ret = 0.0\n        if active:\n            # lending leg: +10MM USD notionally invested in CCY par bond\n            lend_usd = 10_000_000.0\n            units_ccy = lend_usd / usd0\n            p0 = 1.0\n            p1 = price_fixed_bond(coupon_rate=s5_lend, rem_t=5.0 - 1/52, par_curve=crv1, freq=4)\n            lend_end_usd = units_ccy * p1 * usd1\n\n            # borrowing leg: borrow 8MM USD equivalent in GBP, \u0394V=0 in GBP; add 1-week interest accrual\n            borrow_usd0 = 8_000_000.0\n            borrow_gbp_units = borrow_usd0 / gbp0\n            borrow_end_usd = borrow_gbp_units * (1 + fund_spread/52.0) * gbp1\n\n            # equity PnL relative to 2MM equity (10MM asset - 8MM debt)\n            equity0 = 2_000_000.0\n            equity1 = lend_end_usd - borrow_end_usd\n            pnl_usd = equity1 - equity0\n            ret = pnl_usd / equity0\n\n        records.append({\n            'date': t0,\n            'next_date': t1,\n            'ccy': c,\n            'active': int(active),\n            's5_lend': s5_lend,\n            's5_fund_threshold': s5_fund + 0.005,\n            'ois': ois_rate,\n            'fx_usd_per_ccy_t0': usd0,\n            'fx_usd_per_ccy_t1': usd1,\n            'fx_usd_per_gbp_t0': gbp0,\n            'fx_usd_per_gbp_t1': gbp1,\n            'pnl_usd': pnl_usd,\n            'ret': ret\n        })\n        ccy_rets[c] = ret if active else np.nan\n\n    active_rets = [v for v in ccy_rets.values() if np.isfinite(v)]\n    port_ret = float(np.mean(active_rets)) if active_rets else 0.0\n    weekly_port_ret.append({'date': t0, 'portfolio_ret': port_ret, 'active_positions': len(active_rets)})\n\nres = pd.DataFrame(records)\nport = pd.DataFrame(weekly_port_ret).set_index('date').sort_index()\n\nprint('Total currency-week rows:', len(res))\nprint('Active ratio:', res['active'].mean())\nprint('Funding threshold used OIS proxy:', used_funding_proxy)\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "\n# --- Performance analytics + artifacts ---\n\ndef max_drawdown(r):\n    wealth = (1+r.fillna(0)).cumprod()\n    dd = wealth/wealth.cummax() - 1\n    return float(dd.min())\n\nstats = []\npivot_ret = res.pivot(index='date', columns='ccy', values='ret').sort_index()\nfor c in pivot_ret.columns:\n    r = pivot_ret[c].dropna()\n    if len(r) == 0:\n        continue\n    stats.append({\n        'ccy': c,\n        'mean_weekly': r.mean(),\n        'vol_weekly': r.std(ddof=1),\n        'sharpe_weekly': (r.mean()/r.std(ddof=1) if r.std(ddof=1)>0 else np.nan),\n        'max_drawdown': max_drawdown(r),\n        'active_weeks': int(r.notna().sum())\n    })\nstats_df = pd.DataFrame(stats).sort_values('sharpe_weekly', ascending=False)\ncorr = pivot_ret.corr(min_periods=20)\n\nport['wealth'] = (1+port['portfolio_ret']).cumprod()\n\n# drop-one diagnostic\ndiag = []\nbase_sharpe = port['portfolio_ret'].mean()/port['portfolio_ret'].std(ddof=1)\nfor c in pivot_ret.columns:\n    sub = pivot_ret.drop(columns=[c])\n    ew = sub.mean(axis=1, skipna=True).fillna(0)\n    sh = ew.mean()/ew.std(ddof=1) if ew.std(ddof=1)>0 else np.nan\n    diag.append({'ccy': c, 'drop_one_sharpe': sh, 'delta_vs_base': sh-base_sharpe})\ndiag_df = pd.DataFrame(diag).sort_values('delta_vs_base')\n\nstats_df.to_csv(OUT/'currency_stats.csv', index=False)\ncorr.to_csv(OUT/'currency_corr.csv')\nport.reset_index().to_csv(OUT/'portfolio_weekly_returns.csv', index=False)\ndiag_df.to_csv(OUT/'drop_one_diagnostic.csv', index=False)\n\n# figures\nplt.figure(figsize=(9,4))\nplt.plot(port.index, port['wealth'])\nplt.title('FX Carry Portfolio Wealth (weekly EW across active positions)')\nplt.ylabel('Wealth Index')\nplt.tight_layout()\nplt.savefig(FIG/'portfolio_wealth.png', dpi=140)\nplt.close()\n\nplt.figure(figsize=(6,5))\nmat = corr.values\nplt.imshow(mat, cmap='RdBu_r', vmin=-1, vmax=1)\nplt.colorbar(label='Correlation')\nplt.xticks(range(len(corr.columns)), corr.columns, rotation=45, ha='right')\nplt.yticks(range(len(corr.index)), corr.index)\nfor i in range(mat.shape[0]):\n    for j in range(mat.shape[1]):\n        val = mat[i,j]\n        if np.isfinite(val):\n            plt.text(j, i, f'{val:.2f}', ha='center', va='center', fontsize=8)\nplt.title('Currency Return Correlation')\nplt.tight_layout()\nplt.savefig(FIG/'corr_heatmap.png', dpi=140)\nplt.close()\n\nfor c in pivot_ret.columns:\n    w = (1+pivot_ret[c].fillna(0)).cumprod()\n    plt.figure(figsize=(8,3.5))\n    plt.plot(w.index, w.values)\n    plt.title(f'{c} strategy wealth')\n    plt.tight_layout()\n    plt.savefig(FIG/f'currency_wealth_{c}.png', dpi=120)\n    plt.close()\n\nprint('Saved outputs:')\nfor f in sorted(OUT.glob('*.csv')):\n    print(' -', f)\nfor f in sorted(FIG.glob('*.png'))[:5]:\n    print(' -', f)\n\nprint('\\nPortfolio summary:')\nprint(port[['portfolio_ret','active_positions']].describe().T)\nprint('\\nCurrency stats:')\nprint(stats_df)\n"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}