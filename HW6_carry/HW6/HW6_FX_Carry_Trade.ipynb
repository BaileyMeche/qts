{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# HW6 FX Carry (GBP Funding)"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "from pathlib import Path\nimport re\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\npd.set_option('display.width', 220)\npd.set_option('display.max_columns', 200)\n\nBASE = Path('.').resolve()\nOUT = BASE / 'outputs'\nFIG = OUT / 'figures'\nOUT.mkdir(parents=True, exist_ok=True)\nFIG.mkdir(parents=True, exist_ok=True)\n\nprint('PWD:', BASE)\nfor d in [BASE/'data_clean', BASE/'data', BASE/'../../Data']:\n    files = sorted(d.glob('*')) if d.exists() else []\n    print(f'{d} -> {len(files)} files')\n    for f in files[:12]:\n        print('  ', f.name)"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# deterministic file selection\n\ndef pick_file(paths, patterns):\n    tried=[]\n    hits=[]\n    for d in paths:\n        for pat in patterns:\n            tried.append((str(d), pat))\n            if d.exists():\n                hits += list(d.glob(pat))\n    hits = sorted(set(hits), key=lambda x: (x.stat().st_mtime, x.name), reverse=True)\n    print('patterns tried:', tried)\n    print('candidates:', [str(h) for h in hits])\n    if not hits:\n        return None\n    print('chosen:', hits[0])\n    return hits[0]\n\n\ndef load_sonia_overnight():\n    fp=pick_file([BASE/'data_clean'], ['*IUDSOIA*.parquet','*IUDSOIA*.csv'])\n    if fp is None:\n        raise FileNotFoundError('No IUDSOIA file found in data_clean')\n    if fp.suffix=='.parquet':\n        df=pd.read_parquet(fp)\n    else:\n        df=pd.read_csv(fp)\n    if isinstance(df.index, pd.DatetimeIndex):\n        s=pd.Series(pd.to_numeric(df.iloc[:,0],errors='coerce').values, index=pd.to_datetime(df.index, errors='coerce'), name='sonia')\n    else:\n        date_col=next((c for c in df.columns if str(c).upper()=='DATE'), df.columns[0])\n        val_col=next((c for c in df.columns if 'IUDSOIA' in str(c).upper()), [c for c in df.columns if c!=date_col][0])\n        s=pd.Series(pd.to_numeric(df[val_col],errors='coerce').values, index=pd.to_datetime(df[date_col],errors='coerce'), name='sonia')\n    s=s.dropna().sort_index()\n    s.index=s.index.tz_localize(None)\n    if s.median()>1:\n        s=s/100.0\n    return s\n\n\ndef load_gbp_5y_funding(sonia_idx):\n    fp=pick_file([BASE/'data_clean'], ['*boe*ois*daily*raw*.parquet','*ois*daily*raw*.parquet'])\n    if fp is None:\n        inv=[x.name for x in sorted((BASE/'data_clean').glob('*'))]\n        raise RuntimeError('FAIL: no GBP curve file for 5Y funding. inventory='+str(inv))\n    raw=pd.read_parquet(fp)\n    req={'__source_file','__sheet','UK OIS spot curve'}\n    if not req.issubset(raw.columns):\n        raise RuntimeError(f'FAIL: raw OIS columns missing. found={raw.columns.tolist()}')\n\n    sub=raw[raw['__sheet'].astype(str).str.contains('spot curve', case=False, na=False)].copy()\n    if sub.empty:\n        raise RuntimeError('FAIL: no spot curve rows found for GBP funding 5Y')\n\n    pieces=[]\n    for src,g in sub.groupby('__source_file'):\n        vals=pd.to_numeric(g['UK OIS spot curve'], errors='coerce').dropna().reset_index(drop=True)\n        vals=vals[(vals>-5)&(vals<25)]\n        if len(vals)>2 and abs(vals.iloc[0]-1.0)<1e-10 and abs(vals.iloc[1]-1/12)<1e-10:\n            vals=vals.iloc[2:].reset_index(drop=True)\n        if len(vals)<100:\n            continue\n        years=[int(x) for x in re.findall(r'(20\\d{2})', str(src))]\n        if years:\n            y0,y1=min(years),max(years)\n            idx_pool=pd.DatetimeIndex([d for d in sonia_idx if y0<=d.year<=y1])\n        else:\n            idx_pool=sonia_idx\n        if len(idx_pool)<len(vals):\n            idx_pool=sonia_idx[-len(vals):]\n        else:\n            idx_pool=idx_pool[:len(vals)]\n        pieces.append(pd.Series(vals.values, index=idx_pool))\n\n    if not pieces:\n        inv=[x.name for x in sorted((BASE/'data_clean').glob('*'))]\n        raise RuntimeError('FAIL: unable to construct GBP 5Y funding series. inventory='+str(inv)+' cols='+str(raw.columns.tolist()))\n\n    s=pd.concat(pieces).sort_index()\n    s=s[~s.index.duplicated(keep='last')].dropna()\n    if s.median()>1:\n        s=s/100.0\n    s.name='gbp5y_fund'\n    return s\n\n\ndef load_fx_usd_per_ccy(currencies):\n    fp=pick_file([BASE/'data_clean'], ['*usd_per_ccy*wide*.parquet','*edi*cur*fx_long*.parquet'])\n    if fp is None:\n        raise FileNotFoundError('No FX file found in data_clean')\n    if 'fx_long' in fp.name:\n        d=pd.read_parquet(fp)\n        fx=d.pivot(index='date', columns='ccy', values='value')\n    else:\n        fx=pd.read_parquet(fp)\n    if not isinstance(fx.index, pd.DatetimeIndex):\n        fx.index=pd.to_datetime(fx.index, errors='coerce')\n    fx.index=fx.index.tz_localize(None)\n    fx.columns=[str(c).upper().strip() for c in fx.columns]\n    fx=fx.apply(pd.to_numeric, errors='coerce').sort_index()\n\n    keep=sorted(set(currencies+['GBP']))\n    for c in keep:\n        if c not in fx.columns:\n            fx[c]=np.nan\n    fx=fx[keep]\n\n    gbp=fx['GBP'].dropna()\n    frac=gbp.between(0.3,5.0).mean() if len(gbp)>0 else 0\n    if frac<0.95:\n        fx=1.0/fx\n        print('FX auto-inverted based on GBP sanity range')\n    gbp=fx['GBP'].dropna()\n    assert gbp.between(0.3,5.0).mean()>0.95, 'GBP fx quote sanity failed after inversion check'\n\n    jumps=(fx.pct_change().abs()>0.20).sum()\n    print('FX abs return >20% counts:')\n    print(jumps)\n    return fx\n\n\ndef parse_em_curve_csv(fp):\n    raw=pd.read_csv(fp)\n    out=[]\n    cols=list(raw.columns)\n    for i in range(0,len(cols),2):\n        c0=cols[i]\n        c1=cols[i+1] if i+1<len(cols) else None\n        if c1 is None:\n            continue\n        m=re.search(r'GT([A-Z]{3})(\\d+)(Y|YR)', str(c0).upper())\n        if not m:\n            continue\n        tmp=pd.DataFrame({\n            'date':pd.to_datetime(raw[c0], errors='coerce'),\n            'ccy':m.group(1),\n            'tenor':float(m.group(2)),\n            'rate':pd.to_numeric(raw[c1], errors='coerce')\n        }).dropna(subset=['date','rate'])\n        out.append(tmp)\n    if not out:\n        raise RuntimeError('No parsable EM curve columns in '+str(fp))\n    return pd.concat(out, ignore_index=True)\n\n\ndef load_em_curves():\n    dirs=[BASE/'../../Data', BASE/'data', BASE.parent/'data']\n    files=[]\n    for d in dirs:\n        if d.exists():\n            files += list(d.glob('*Emerging*Mkt*YC*.csv'))\n    files=sorted(set(files), key=lambda x:(x.stat().st_mtime,x.name), reverse=True)\n    if not files:\n        raise FileNotFoundError('No EM YC files in ../../Data or ./data')\n    print('EM curve files:', [f.name for f in files])\n    df=pd.concat([parse_em_curve_csv(f) for f in files], ignore_index=True)\n    if df['rate'].median()>1:\n        df['rate']=df['rate']/100.0\n    df['date']=pd.to_datetime(df['date']).dt.tz_localize(None)\n    return df.groupby(['date','ccy','tenor'], as_index=False)['rate'].mean()\n\nEM=['BRL','NGN','PKR','TRY','ZAR']\nsonia=load_sonia_overnight()\ngbp5=load_gbp_5y_funding(sonia.index)\nfx=load_fx_usd_per_ccy(EM)\ncurves=load_em_curves()\n\nprint('coverage sonia',sonia.index.min().date(),sonia.index.max().date(),len(sonia))\nprint('coverage gbp5 ',gbp5.index.min().date(),gbp5.index.max().date(),len(gbp5))\nprint('coverage fx   ',fx.index.min().date(),fx.index.max().date(),len(fx))\nprint('coverage curve',curves.date.min().date(),curves.date.max().date(),len(curves))"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# weekly alignment\n\ndef align_weekly(obj, start, end, tol=2):\n    target=pd.date_range(start,end,freq='W-WED')\n    out=[]; idx=[]\n    for d in target:\n        cand=[d+pd.Timedelta(days=k) for k in [0,1,2,-1,-2] if abs(k)<=tol]\n        c=next((x for x in cand if x in obj.index), None)\n        if c is None:\n            continue\n        out.append(obj.loc[c]); idx.append(d)\n    if isinstance(obj,pd.Series):\n        return pd.Series(out,index=pd.DatetimeIndex(idx),name=obj.name)\n    return pd.DataFrame(out,index=pd.DatetimeIndex(idx),columns=obj.columns)\n\ncurve_w=curves.pivot_table(index=['date','ccy'], columns='tenor', values='rate', aggfunc='mean').sort_index()\nstart=max(sonia.index.min(), gbp5.index.min(), fx.index.min(), curves.date.min())\nend=min(sonia.index.max(), gbp5.index.max(), fx.index.max(), curves.date.max())\n\nsonia_w=align_weekly(sonia,start,end)\ngbp5_w=align_weekly(gbp5,start,end)\nfx_w=align_weekly(fx,start,end)\ndates=sonia_w.index.intersection(gbp5_w.index).intersection(fx_w.index)\n\ncurve_ccy={}\nfor c in EM:\n    if c not in curve_w.index.get_level_values('ccy'):\n        continue\n    cdf=align_weekly(curve_w.xs(c,level='ccy'),start,end)\n    curve_ccy[c]=cdf.reindex(dates).ffill()\n\nsonia_w=sonia_w.reindex(dates).ffill(); gbp5_w=gbp5_w.reindex(dates).ffill(); fx_w=fx_w.reindex(dates).ffill()\n\nprint('weekly n=',len(dates),dates.min().date(),dates.max().date())\nprint('missing sonia',int(sonia_w.isna().sum()),'gbp5',int(gbp5_w.isna().sum()))\nprint('missing fx\\n',fx_w.isna().sum())\nfor c in curve_ccy:\n    print(c,'curve missing rows',int(curve_ccy[c].isna().any(axis=1).sum()))"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# curve and pricing\n\ndef interp_rate(tenors, rates, t):\n    x=np.array(tenors,dtype=float); y=np.array(rates,dtype=float)\n    m=np.isfinite(x)&np.isfinite(y)\n    x=x[m]; y=y[m]\n    if len(x)==0:\n        return np.nan\n    o=np.argsort(x); x=x[o]; y=y[o]\n    return float(np.interp(t,x,y,left=y[0],right=y[-1]))\n\ndef bootstrap_df_from_par(par_curve, freq=4, max_t=5.0):\n    grid=np.arange(1/freq,max_t+1e-12,1/freq)\n    dfs={}\n    for t in grid:\n        s=interp_rate(par_curve.index.values, par_curve.values, t)\n        c=s/freq\n        pv_prev=sum(c*dfs[pt] for pt in grid if pt<t)\n        dfs[t]=max((1-pv_prev)/(1+c),1e-12)\n    return pd.Series(dfs)\n\ndef price_bond(coupon_rate, par_curve, times, freq=4):\n    if len(times)==0:\n        return 1.0\n    z=bootstrap_df_from_par(par_curve,freq=freq,max_t=max(5.0,float(np.max(times))+0.25))\n    df=np.interp(times,z.index.values,z.values,left=z.values[0],right=z.values[-1])\n    cf=np.full(len(times),coupon_rate/freq); cf[-1]+=1.0\n    return float(np.sum(cf*df))\n\ntimes_entry=np.arange(0.25,5.0+1e-12,0.25)\ndt=1/52\ntimes_exit_full=times_entry-dt\ntimes_exit=times_exit_full[times_exit_full>0]\nprint('entry head/tail',times_entry[:5],times_entry[-5:])\nprint('exit  head/tail',times_exit_full[:5],times_exit_full[-5:])\nassert np.max(np.abs((times_entry-dt)-times_exit_full))<1e-12\n\n# par sanity\ndiag=[]\nrng=np.random.default_rng(1)\nfor c in EM:\n    if c not in curve_ccy: continue\n    cdf=curve_ccy[c].dropna(how='all')\n    if cdf.empty: continue\n    for k in rng.choice(len(cdf), size=min(4,len(cdf)), replace=False):\n        row=cdf.iloc[int(k)].dropna()\n        s5=interp_rate(row.index.values,row.values,5.0)\n        p0=price_bond(s5,row,times_entry)\n        diag.append({'ccy':c,'date':cdf.index[int(k)],'s5':s5,'entry_pv':p0,'dev':p0-1})\npar_diag=pd.DataFrame(diag)\nprint(par_diag.head())\nprint('entry par pv min/max',par_diag['entry_pv'].min(),par_diag['entry_pv'].max())"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# strategy simulation\nrows=[]; plist=[]\nfor i in range(len(dates)-1):\n    t0,t1=dates[i],dates[i+1]\n    s5_fund=float(gbp5_w.loc[t0])\n    ois=float(sonia_w.loc[t0])\n    borrow_rate=ois+0.005\n    active=0\n    rlist=[]\n    spread_list=[]\n    for c in EM:\n        if c not in curve_ccy: continue\n        c0=curve_ccy[c].loc[t0].dropna(); c1=curve_ccy[c].loc[t1].dropna()\n        if c0.empty or c1.empty:\n            continue\n        s5_lend=interp_rate(c0.index.values,c0.values,5.0)\n        spread=s5_lend-s5_fund\n        trade=bool(np.isfinite(s5_lend) and np.isfinite(s5_fund) and spread>=0.005)\n\n        fx0=fx_w.at[t0,c]; fx1=fx_w.at[t1,c]\n        gbp0=fx_w.at[t0,'GBP']; gbp1=fx_w.at[t1,'GBP']\n        if not np.isfinite([fx0,fx1,gbp0,gbp1]).all():\n            trade=False\n\n        ret=np.nan; pnl=0.0\n        if trade:\n            units_ccy=10_000_000/fx0\n            p1=price_bond(s5_lend,c1,times_exit)\n            lend_end=units_ccy*p1*fx1\n\n            debt_units=8_000_000/gbp0\n            debt_end=debt_units*(1+borrow_rate/52)*gbp1\n\n            eq0=2_000_000\n            eq1=lend_end-debt_end\n            pnl=eq1-eq0\n            ret=pnl/eq0\n            active+=1\n            rlist.append(ret)\n        spread_list.append(spread)\n        rows.append({'date':t0,'next_date':t1,'ccy':c,'active':int(trade),'s5_lend':s5_lend,'s5_fund':s5_fund,'spread':spread,'entry_hurdle':s5_fund+0.005,'ois':ois,'borrow_rate':borrow_rate,'ret':ret,'pnl_usd':pnl})\n\n    plist.append({'date':t0,'port_ret':(float(np.mean(rlist)) if rlist else 0.0),'active_positions':active,'spread_mean':(float(np.mean(spread_list)) if spread_list else np.nan)})\n\nres=pd.DataFrame(rows)\nport=pd.DataFrame(plist).set_index('date').sort_index()\nport['wealth']=(1+port['port_ret']).cumprod()\nport['drawdown']=port['wealth']/port['wealth'].cummax()-1\nassert float(port['drawdown'].min()) >= -1-1e-12\n\nactive_diag=res.groupby('ccy',as_index=False)['active'].mean().rename(columns={'active':'active_frac'})\navg_active=port['active_positions'].mean()\nactive_diag.loc[len(active_diag)]={'ccy':'ALL_AVG_ACTIVE_POSITIONS','active_frac':avg_active}\nif avg_active>4.9:\n    print('WARNING avg active > 4.9; spread diagnostics:')\n    print(res.groupby('ccy')['spread'].describe())\n\nactive_diag.to_csv(OUT/'active_diagnostics.csv',index=False)\nprint(active_diag)"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# analytics + artifacts\n\ndef ann_sharpe(r):\n    s=r.std(ddof=1)\n    return np.sqrt(52)*r.mean()/s if s>0 else np.nan\n\ndef maxdd(r):\n    w=(1+r.fillna(0)).cumprod()\n    return float((w/w.cummax()-1).min())\n\npivot=res.pivot(index='date',columns='ccy',values='ret').sort_index()\n\nstats=[]\nfor c in pivot.columns:\n    rr=pivot[c].dropna()\n    if len(rr)==0: continue\n    stats.append({'ccy':c,'mean_weekly':rr.mean(),'vol_weekly':rr.std(ddof=1),'ann_sharpe':ann_sharpe(rr),'active_frac':float(res.loc[res.ccy==c,'active'].mean()),'pnl_sum_usd':float(res.loc[res.ccy==c,'pnl_usd'].sum()),'max_dd_wealth':maxdd(rr),'active_weeks':int(rr.notna().sum())})\nstats_df=pd.DataFrame(stats).sort_values('ann_sharpe',ascending=False)\n\ncorr=pivot.corr(min_periods=25)\nbase=port['port_ret']; base_sh=ann_sharpe(base); base_dd=float(port['drawdown'].min())\n\ndrop=[]\nfor c in pivot.columns:\n    ew=pivot.drop(columns=[c]).mean(axis=1,skipna=True).fillna(0)\n    w=(1+ew).cumprod(); dd=float((w/w.cummax()-1).min())\n    sh=ann_sharpe(ew)\n    drop.append({'ccy_removed':c,'ann_sharpe_drop_one':sh,'max_dd_drop_one':dd,'delta_sharpe':sh-base_sh,'delta_dd':dd-base_dd})\ndrop_df=pd.DataFrame(drop).sort_values('delta_sharpe')\n\nport_out=port.reset_index()\nstats_df.to_csv(OUT/'currency_stats.csv',index=False)\ncorr.to_csv(OUT/'currency_corr.csv')\ndrop_df.to_csv(OUT/'drop_one_diagnostic.csv',index=False)\nport_out.to_csv(OUT/'portfolio_weekly_returns.csv',index=False)\n\nplt.figure(figsize=(9,4)); plt.plot(port.index,port['wealth']); plt.title('Portfolio wealth'); plt.tight_layout(); plt.savefig(FIG/'portfolio_wealth.png',dpi=130); plt.close()\nplt.figure(figsize=(9,4)); plt.plot(port.index,port['drawdown']); plt.title('Portfolio drawdown'); plt.tight_layout(); plt.savefig(FIG/'portfolio_drawdown.png',dpi=130); plt.close()\nplt.figure(figsize=(9,4)); plt.plot(port.index,port['active_positions']); plt.title('Active positions per week'); plt.tight_layout(); plt.savefig(FIG/'active_positions.png',dpi=130); plt.close()\nplt.figure(figsize=(6,5)); mat=corr.values; plt.imshow(mat,cmap='RdBu_r',vmin=-1,vmax=1); plt.colorbar(); plt.xticks(range(len(corr.columns)),corr.columns,rotation=45,ha='right'); plt.yticks(range(len(corr.index)),corr.index)\nfor i in range(mat.shape[0]):\n    for j in range(mat.shape[1]):\n        if np.isfinite(mat[i,j]): plt.text(j,i,f'{mat[i,j]:.2f}',ha='center',va='center',fontsize=8)\nplt.tight_layout(); plt.savefig(FIG/'corr_heatmap.png',dpi=130); plt.close()\n\nprint('core artifacts written')"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# market factors\nhits=[]\nfor pat in ['*VIX*','*DXY*','*SPX*','*MSCI*','*UST*','*rates*','*factor*']:\n    hits += list((BASE/'data_clean').glob(pat))\nprint('factor hits:', [h.name for h in sorted(set(hits))])\n\n# proxy factors (if no external found)\nem_basket=np.log(fx_w[EM]).diff().mean(axis=1)\nusd_gbp=-np.log(fx_w['GBP']).diff()\nproxy_usd=0.5*usd_gbp + 0.5*em_basket\nproxy_rates_ois=sonia_w.diff()\nproxy_rates_5y=gbp5_w.diff()\n\nfactors=pd.DataFrame({'proxy_usd_broad':proxy_usd,'proxy_em_risk':em_basket,'proxy_d_ois':proxy_rates_ois,'proxy_d_gbp5y':proxy_rates_5y},index=port.index)\n\nmf=pd.concat([port['port_ret'],factors],axis=1).dropna()\nmcorr=mf.corr().loc[factors.columns,['port_ret']].rename(columns={'port_ret':'corr_with_port'})\nmcorr.to_csv(OUT/'market_factor_corr.csv')\n\nrows=[]\ny=mf['port_ret'].values\nfor fac in factors.columns:\n    x=mf[[fac]].values[:,0]\n    X=np.column_stack([np.ones(len(x)),x])\n    b=np.linalg.lstsq(X,y,rcond=None)[0]\n    yh=X@b; e=y-yh\n    n=len(y); k=2\n    s2=(e@e)/(n-k)\n    cov=s2*np.linalg.inv(X.T@X)\n    se=np.sqrt(np.diag(cov))\n    t=b[1]/se[1] if se[1]>0 else np.nan\n    r2=1-(e@e)/np.sum((y-y.mean())**2)\n    rows.append({'model':'univariate','factor':fac,'alpha':b[0],'beta':b[1],'t_beta':t,'r2':r2,'n':n})\n\nX=np.column_stack([np.ones(len(mf))]+[mf[c].values for c in factors.columns])\nb=np.linalg.lstsq(X,y,rcond=None)[0]\nyh=X@b; e=y-yh\nn=len(y); k=X.shape[1]\ns2=(e@e)/(n-k)\ncov=s2*np.linalg.inv(X.T@X)\nse=np.sqrt(np.diag(cov)); r2=1-(e@e)/np.sum((y-y.mean())**2)\nlabels=['const']+list(factors.columns)\nfor j,lab in enumerate(labels):\n    rows.append({'model':'multivariate','factor':lab,'alpha':b[0],'beta':b[j],'t_beta':(b[j]/se[j] if se[j]>0 else np.nan),'r2':r2,'n':n})\nreg=pd.DataFrame(rows)\nreg.to_csv(OUT/'market_factor_regs.csv',index=False)\n\nfor fac in factors.columns:\n    tmp=mf[['port_ret',fac]].dropna()\n    plt.figure(figsize=(5,4)); plt.scatter(tmp[fac],tmp['port_ret'],s=10,alpha=0.6)\n    z=np.polyfit(tmp[fac],tmp['port_ret'],1); xs=np.linspace(tmp[fac].min(),tmp[fac].max(),100)\n    plt.plot(xs,z[0]*xs+z[1],color='red'); plt.xlabel(fac); plt.ylabel('port_ret'); plt.tight_layout(); plt.savefig(FIG/f'factor_scatter_{fac}.png',dpi=120); plt.close()\n\nprint(mcorr)\nprint(reg.head(10))"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# write markdown report from outputs\nstats=pd.read_csv(OUT/'currency_stats.csv')\ncorr=pd.read_csv(OUT/'currency_corr.csv',index_col=0)\ndrop=pd.read_csv(OUT/'drop_one_diagnostic.csv')\nport_csv=pd.read_csv(OUT/'portfolio_weekly_returns.csv',parse_dates=['date'])\nmc=pd.read_csv(OUT/'market_factor_corr.csv',index_col=0)\nmr=pd.read_csv(OUT/'market_factor_regs.csv')\nactive=pd.read_csv(OUT/'active_diagnostics.csv')\n\n\ndef md_table(df, nd=6):\n    cols=list(df.columns)\n    lines=['| '+' | '.join(cols)+' |','|'+'|'.join(['---']*len(cols))+'|']\n    for _,r in df.iterrows():\n        vals=[]\n        for c in cols:\n            v=r[c]\n            if isinstance(v,float): vals.append(f'{v:.{nd}f}')\n            else: vals.append(str(v))\n        lines.append('| '+' | '.join(vals)+' |')\n    return '\\\\n'.join(lines)\n\nr=port_csv['port_ret']\nann_ret=r.mean()*52\nann_vol=r.std(ddof=1)*np.sqrt(52)\nann_sh=ann_ret/ann_vol if ann_vol>0 else np.nan\n\ntext=[]\ntext.append('# HW6 FX Carry Report')\ntext.append('## 1) Spec recap')\ntext.append('- Weekly strategy; lend $10MM in EM 5Y par bond, fund $8MM in GBP at OIS+50bp, equity $2MM.')\ntext.append('- Entry filter uses true GBP 5Y funding series: trade if s5_lend >= s5_fund + 50bp.')\ntext.append('- MTM uses explicit quarterly schedule shifted by 1/52 at exit; no separate accrual added to lending leg.')\ntext.append('- USD accounting for all PnL and portfolio aggregation.')\ntext.append('## 2) Data & coverage')\ntext.append(f\"- Weekly sample: {port_csv['date'].min().date()} to {port_csv['date'].max().date()}, N={len(port_csv)}.\")\ntext.append('- Inputs loaded from ./data_clean/ and curves from ../../Data/ or ./data fallback.')\ntext.append('## 3) Methodology')\ntext.append('- Curve pricing uses linear interpolation + recursive discount bootstrap from par rates (Zero/Spot style).')\ntext.append('- Cashflow shift validation shown in notebook output (entry and exit times).')\ntext.append('- GBP 5Y funding built from local BoE OIS spot-curve archive (not overnight proxy).')\ntext.append('## 4) Results')\ntext.append(md_table(stats))\ntext.append('| metric | value |')\ntext.append('|---|---:|')\ntext.append(f'| ann return | {ann_ret:.6f} |')\ntext.append(f'| ann vol | {ann_vol:.6f} |')\ntext.append(f'| ann sharpe | {ann_sh:.6f} |')\ntext.append(f\"| max drawdown | {port_csv['drawdown'].min():.6f} |\")\ntext.append('![wealth](outputs/figures/portfolio_wealth.png)')\ntext.append('![drawdown](outputs/figures/portfolio_drawdown.png)')\ntext.append('![active](outputs/figures/active_positions.png)')\ntext.append('![corr](outputs/figures/corr_heatmap.png)')\ntext.append('## 5) Correlation and drop-one')\ntext.append(md_table(corr.reset_index().rename(columns={corr.index.name or 'index':'ccy'}), nd=3))\ntext.append(md_table(drop))\ntext.append('## 6) Market Factors')\ntext.append('- No external factor files found; used labeled proxy factors.')\ntext.append(md_table(mc.reset_index()))\ntext.append(md_table(mr))\ntext.append('Carry/crash interpretation: FX/risk proxies explain part of variation; carry can be dominated by adverse FX shocks in risk-off episodes.')\ntext.append('## 7) Robustness & limitations')\ntext.append('- FX inversion checks, >20% move flags, weekly missingness diagnostics, par PV sanity, and drawdown assertion included.')\ntext.append('- Limitation: available local GBP curve data is reconstructed from BoE raw archive format and may not provide full pillar metadata.')\ntext.append('')\n\n(BASE/'hw6_fx_carry_report.md').write_text('\\n\\n'.join(text))\nprint('report written to', BASE/'hw6_fx_carry_report.md')"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}